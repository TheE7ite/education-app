{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOO+JPMj4Ze5KACVNhiCp0B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheE7ite/education-app/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import openai\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import torch\n",
        "\n",
        "# Initialize the OpenAI API client\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "# Initialize the question answering model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "def main():\n",
        "    # Set the page title and header\n",
        "    st.title(\"AI Education Tool\")\n",
        "    st.header(\"Enter a topic and I'll generate a context, question, and assess your answer.\")\n",
        "\n",
        "    # Get the topic from the user\n",
        "    topic = st.text_input(\"Topic:\")\n",
        "\n",
        "    # Generate the context, question, and answer\n",
        "    context = generate_context(topic)\n",
        "    question = generate_question(context)\n",
        "    answer = generate_answer(context, question)\n",
        "\n",
        "    # Display the context, question, and answer to the user\n",
        "    st.write(\"**Context:**\")\n",
        "    st.write(context)\n",
        "    st.write(\"**Question:**\")\n",
        "    st.write(question)\n",
        "    st.write(\"**Answer:**\")\n",
        "    st.write(answer)\n",
        "\n",
        "    # Get the user's answer\n",
        "    user_answer = st.text_input(\"Your Answer:\")\n",
        "\n",
        "    # Assess the user's answer\n",
        "    assessment = assess_answer(user_answer, answer)\n",
        "\n",
        "    # Display the assessment to the user\n",
        "    st.write(\"**Assessment:**\")\n",
        "    st.write(assessment)\n",
        "\n",
        "def generate_context(topic):\n",
        "    prompt = f\"Generate a short context about {topic}.\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\":\"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def generate_question(context):\n",
        "    prompt = f\"Generate a multiple-choice question based on the following context:\\n\\n{context}\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\":\"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def generate_answer(context, question):\n",
        "  prompt = f\"Answer the following question based on the provided context:\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\"\n",
        "  response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "  )\n",
        "  return response.choices[0][\"message\"][\"content\"]\n",
        "\n",
        "def assess_answer(user_answer, answer):\n",
        "  if user_answer == answer:\n",
        "        return \"Correct!\"\n",
        "  else:\n",
        "        return \"Incorrect. The correct answer is: \" + answer\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "h_j8UmEQFgpw"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}